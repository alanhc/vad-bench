<!doctype html>
<html lang="zh-Hant">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>VAD Benchmark (WebRTC VAD vs Silero vs Energy)</title>
  <style>
    :root {
      --bg: #0b0f17;
      --fg: #e7eaf0;
      --muted: #9aa4b2;
      --card: #121a2a;
      --border: #23304a;
      --ok: #32d583;
      --warn: #fdb022;
    }

    body {
      margin: 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Noto Sans TC", "PingFang TC", sans-serif;
      background: var(--bg);
      color: var(--fg);
    }

    header {
      padding: 20px 20px 10px;
      border-bottom: 1px solid var(--border);
    }

    h1 {
      margin: 0 0 6px;
      font-size: 20px;
    }

    .sub {
      color: var(--muted);
      font-size: 13px;
      line-height: 1.4;
    }

    main {
      padding: 20px;
      display: grid;
      grid-template-columns: 420px 1fr;
      gap: 16px;
    }

    @media (max-width: 980px) {
      main {
        grid-template-columns: 1fr;
      }
    }

    .card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 14px;
      padding: 14px;
    }

    .row {
      display: flex;
      gap: 10px;
      align-items: center;
      flex-wrap: wrap;
    }

    label {
      font-size: 12px;
      color: var(--muted);
      display: block;
      margin-bottom: 6px;
    }

    input[type="number"],
    input[type="text"],
    select {
      width: 100%;
      padding: 10px;
      border-radius: 10px;
      border: 1px solid var(--border);
      background: #0b1220;
      color: var(--fg);
      outline: none;
    }

    input[type="file"] {
      width: 100%;
      color: var(--muted);
    }

    button {
      padding: 10px 12px;
      border-radius: 10px;
      border: 1px solid var(--border);
      background: #0b1220;
      color: var(--fg);
      cursor: pointer;
    }

    button.primary {
      background: #12315e;
      border-color: #1f4b88;
    }

    button:disabled {
      opacity: .5;
      cursor: not-allowed;
    }

    .mono {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
    }

    .kv {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 10px;
    }

    .kv3 {
      display: grid;
      grid-template-columns: 1fr 1fr 1fr;
      gap: 10px;
    }

    .hr {
      height: 1px;
      background: var(--border);
      margin: 12px 0;
    }

    .status {
      font-size: 13px;
      color: var(--muted);
      line-height: 1.5;
    }

    .status b {
      color: var(--fg);
    }

    .pill {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      font-size: 12px;
      border: 1px solid var(--border);
      color: var(--muted);
    }

    .pill.ok {
      color: var(--ok);
      border-color: rgba(50, 213, 131, .35);
    }

    .pill.warn {
      color: var(--warn);
      border-color: rgba(253, 176, 34, .35);
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 13px;
    }

    th,
    td {
      padding: 10px;
      border-bottom: 1px solid var(--border);
      vertical-align: top;
    }

    th {
      text-align: left;
      color: var(--muted);
      font-weight: 600;
    }

    .right {
      text-align: right;
    }

    canvas {
      width: 100%;
      height: 260px;
      background: #070a11;
      border: 1px solid var(--border);
      border-radius: 12px;
    }

    textarea {
      width: 100%;
      min-height: 140px;
      padding: 10px;
      border-radius: 12px;
      border: 1px solid var(--border);
      background: #0b1220;
      color: var(--fg);
      outline: none;
    }

    .small {
      font-size: 12px;
      color: var(--muted);
    }

    .hint {
      font-size: 12px;
      color: var(--muted);
      line-height: 1.5;
    }

    .good {
      color: var(--ok);
    }

    .bad {
      color: var(--warn);
    }
  </style>

  <!-- Silero VAD via vad-web + onnxruntime-web (CDN quick start) -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.22.0/dist/ort.wasm.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.29/dist/bundle.min.js"></script>
</head>

<body>
  <header>
    <h1>VAD Benchmark（WebRTC VAD vs Silero vs Energy baseline）</h1>
    <div class="sub">
      檔案離線 benchmark：跑完會輸出耗時 / RTF / 段落 / speech 時長 / 幀耗時統計，並畫出 timeline。<br />
      Silero 由 <span class="mono">@ricky0123/vad-web</span> 在瀏覽器內用 ONNX Runtime Web 執行，
      WebRTC VAD 由 <span class="mono">@ozymandiasthegreat/vad</span>（libfvad WASM）執行。
    </div>
  </header>

  <main>
    <section class="card">
      <div class="row">
        <div style="flex:1">
          <label>音檔（建議 wav / mp3；會自動轉 mono + resample → 16kHz）</label>
          <input id="audioFile" type="file" accept="audio/*" />
        </div>
      </div>

      <div class="hr"></div>

      <div class="kv">
        <div>
          <label>WebRTC VAD mode</label>
          <select id="webrtcMode">
            <option value="0">0 - NORMAL</option>
            <option value="1">1 - LOW_BITRATE</option>
            <option value="2" selected>2 - AGGRESSIVE</option>
            <option value="3">3 - VERY_AGGRESSIVE</option>
          </select>
        </div>
        <div>
          <label>WebRTC frame (ms)</label>
          <select id="webrtcFrameMs">
            <option value="10" selected>10ms (160 samples @16k)</option>
            <option value="20">20ms (320 samples @16k)</option>
            <option value="30">30ms (480 samples @16k)</option>
          </select>
        </div>
      </div>

      <div class="hr"></div>

      <div class="kv3">
        <div>
          <label>Silero pos threshold</label>
          <input id="sileroPos" type="number" step="0.01" value="0.5" />
        </div>
        <div>
          <label>Silero neg threshold</label>
          <input id="sileroNeg" type="number" step="0.01" value="0.35" />
        </div>
        <div>
          <label>Silero frameSamples</label>
          <select id="sileroFrameSamples">
            <option value="256">256 (~16ms)</option>
            <option value="512" selected>512 (~32ms)</option>
            <option value="768">768 (~48ms)</option>
          </select>
        </div>
      </div>

      <div class="kv3" style="margin-top:10px">
        <div>
          <label>minSpeechMs</label>
          <input id="sileroMinSpeechMs" type="number" step="10" value="250" />
        </div>
        <div>
          <label>preSpeechPadMs</label>
          <input id="sileroPadMs" type="number" step="10" value="120" />
        </div>
        <div>
          <label>redemptionMs</label>
          <input id="sileroRedeemMs" type="number" step="10" value="90" />
        </div>
      </div>

      <div class="hr"></div>

      <div class="kv3">
        <div>
          <label>Energy RMS threshold</label>
          <input id="energyThr" type="number" step="0.0001" value="0.012" />
        </div>
        <div>
          <label>Energy startHangover (frames)</label>
          <input id="energyStartHang" type="number" step="1" value="3" />
        </div>
        <div>
          <label>Energy endHangover (frames)</label>
          <input id="energyEndHang" type="number" step="1" value="6" />
        </div>
      </div>

      <div class="hr"></div>

      <div class="row">
        <button class="primary" id="runBtn">Run benchmark</button>
        <button id="exportBtn" disabled>Export JSON</button>
        <span id="libStatus" class="pill">libs: not checked</span>
      </div>

      <div class="hr"></div>

      <div>
        <label>（可選）Ground truth JSON（格式：[{ "startMs": 1200, "endMs": 3100 }, ...]）</label>
        <input id="gtFile" type="file" accept="application/json,.json" />
        <div class="hint">
          有 GT 時會算 P/R/F1（10ms 格網，未做 collar；你可自行加容忍邊界邏輯）。<br />
          若沒有 GT，也可先用 timeline 目測比較各 VAD 的切段行為。
        </div>
      </div>

      <div class="hr"></div>
      <div class="status" id="status"></div>
    </section>

    <section class="card">
      <div class="row" style="justify-content:space-between">
        <div>
          <div class="pill ok">timeline</div>
          <div class="pill">16kHz mono</div>
          <div class="pill">offline</div>
        </div>
        <audio id="player" controls style="width:320px; max-width:100%"></audio>
      </div>

      <div style="margin-top:10px">
        <canvas id="timeline" width="1400" height="260"></canvas>
        <div class="small" style="margin-top:6px">
          每列一種 VAD：顯示偵測到的 speech segments（條狀）。如有 GT 會多一列。
        </div>
      </div>

      <div class="hr"></div>

      <div>
        <h3 style="margin:0 0 8px; font-size:15px;">Benchmark metrics</h3>
        <div style="overflow:auto">
          <table id="metricsTable">
            <thead>
              <tr>
                <th>Method</th>
                <th class="right">Total time</th>
                <th class="right">RTF</th>
                <th class="right">Segments</th>
                <th class="right">Speech (s)</th>
                <th class="right">Frame p50 / p95</th>
                <th class="right">P/R/F1 (if GT)</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>

      <div class="hr"></div>

      <div>
        <h3 style="margin:0 0 8px; font-size:15px;">Export</h3>
        <textarea id="exportBox" class="mono" placeholder="按 Export JSON 產生結果"></textarea>
        <div class="small">
          你可以把這份 JSON commit 到 repo，當作不同瀏覽器/不同機器的可重現 benchmark 結果。
        </div>
      </div>
    </section>
  </main>

  <script type="module">
    const $ = (id) => document.getElementById(id);

    const audioFileEl = $("audioFile");
    const gtFileEl = $("gtFile");
    const runBtn = $("runBtn");
    const exportBtn = $("exportBtn");
    const statusEl = $("status");
    const libStatusEl = $("libStatus");
    const playerEl = $("player");
    const timeline = $("timeline");
    const metricsTableBody = $("metricsTable").querySelector("tbody");
    const exportBox = $("exportBox");

    const CFG = {
      TARGET_SR: 16000,
      GRID_MS: 10,
    };

    function fmtMs(ms) { return `${ms.toFixed(1)} ms`; }
    function clamp(x, a, b) { return Math.max(a, Math.min(b, x)); }

    function percentile(sorted, p) {
      if (!sorted.length) return NaN;
      const idx = (sorted.length - 1) * p;
      const lo = Math.floor(idx), hi = Math.ceil(idx);
      if (lo === hi) return sorted[lo];
      return sorted[lo] + (sorted[hi] - sorted[lo]) * (idx - lo);
    }

    function toMonoFloat32(audioBuffer) {
      const ch = audioBuffer.numberOfChannels;
      const len = audioBuffer.length;
      const out = new Float32Array(len);
      if (ch === 1) {
        out.set(audioBuffer.getChannelData(0));
        return out;
      }
      for (let c = 0; c < ch; c++) {
        const data = audioBuffer.getChannelData(c);
        for (let i = 0; i < len; i++) out[i] += data[i] / ch;
      }
      return out;
    }

    // Simple linear resampler (enough for benchmark UI)
    function resampleLinear(input, inRate, outRate) {
      if (inRate === outRate) return input;
      const ratio = outRate / inRate;
      const outLen = Math.max(1, Math.floor(input.length * ratio));
      const out = new Float32Array(outLen);
      for (let i = 0; i < outLen; i++) {
        const t = i / ratio;
        const i0 = Math.floor(t);
        const i1 = Math.min(input.length - 1, i0 + 1);
        const a = t - i0;
        out[i] = input[i0] * (1 - a) + input[i1] * a;
      }
      return out;
    }

    function floatToInt16PCM(float32) {
      const out = new Int16Array(float32.length);
      for (let i = 0; i < float32.length; i++) {
        const s = clamp(float32[i], -1, 1);
        out[i] = s < 0 ? Math.round(s * 32768) : Math.round(s * 32767);
      }
      return out;
    }

    function segmentsFromFrameLabels(frameLabels, frameMs) {
      const segs = [];
      let inSpeech = false;
      let startMs = 0;
      for (let i = 0; i < frameLabels.length; i++) {
        const t0 = i * frameMs;
        const t1 = (i + 1) * frameMs;
        const v = frameLabels[i] ? 1 : 0;
        if (!inSpeech && v) {
          inSpeech = true;
          startMs = t0;
        } else if (inSpeech && !v) {
          inSpeech = false;
          segs.push({ startMs, endMs: t0 });
        }
        if (i === frameLabels.length - 1 && inSpeech) {
          segs.push({ startMs, endMs: t1 });
        }
      }
      return segs;
    }

    function sumSpeechSeconds(segs) {
      let ms = 0;
      for (const s of segs) ms += Math.max(0, s.endMs - s.startMs);
      return ms / 1000;
    }

    function frameTimesStats(frameTimesMs) {
      const s = [...frameTimesMs].sort((a, b) => a - b);
      return {
        p50: percentile(s, 0.50),
        p95: percentile(s, 0.95),
        mean: s.length ? s.reduce((x, y) => x + y, 0) / s.length : NaN,
      };
    }

    // === Ground truth scoring (10ms grid) ===
    function segmentsToGrid(segs, totalMs, gridMs) {
      const n = Math.ceil(totalMs / gridMs);
      const g = new Uint8Array(n);
      for (const s of segs) {
        const a = Math.max(0, Math.floor(s.startMs / gridMs));
        const b = Math.min(n, Math.ceil(s.endMs / gridMs));
        for (let i = a; i < b; i++) g[i] = 1;
      }
      return g;
    }

    function prf1(pred, gt) {
      let tp = 0, fp = 0, fn = 0;
      for (let i = 0; i < pred.length; i++) {
        const p = pred[i], g = gt[i];
        if (p && g) tp++;
        else if (p && !g) fp++;
        else if (!p && g) fn++;
      }
      const prec = tp + fp ? tp / (tp + fp) : 0;
      const rec = tp + fn ? tp / (tp + fn) : 0;
      const f1 = (prec + rec) ? 2 * prec * rec / (prec + rec) : 0;
      return { prec, rec, f1 };
    }

    // === WebRTC VAD (libfvad wasm) ===
    async function loadWebRtcVad() {
      const urls = [
        "https://cdn.jsdelivr.net/npm/@ozymandiasthegreat/vad@2.0.7/lib/embedded.js",
        "https://cdn.jsdelivr.net/npm/@ozymandiasthegreat/vad@2.0.7/lib/index.js",
      ];
      let mod = null;
      let lastErr = null;
      for (const u of urls) {
        try {
          mod = await import(u);
          return mod;
        } catch (e) {
          lastErr = e;
        }
      }
      throw lastErr ?? new Error("Failed to import WebRTC VAD module");
    }

    function runEnergyVad(float16k, frameMs, rmsThr, startHang, endHang) {
      const frameSamples = Math.round(CFG.TARGET_SR * (frameMs / 1000));
      const nFrames = Math.floor(float16k.length / frameSamples);
      const labels = new Uint8Array(nFrames);

      const raw = new Uint8Array(nFrames);
      const frameTimes = new Float32Array(nFrames);

      for (let i = 0; i < nFrames; i++) {
        const t0 = performance.now();
        let sumSq = 0;
        const off = i * frameSamples;
        for (let j = 0; j < frameSamples; j++) {
          const s = float16k[off + j];
          sumSq += s * s;
        }
        const rms = Math.sqrt(sumSq / frameSamples);
        raw[i] = rms >= rmsThr ? 1 : 0;
        frameTimes[i] = performance.now() - t0;
      }

      let inSpeech = false;
      let voiceCount = 0;
      let silenceCount = 0;

      for (let i = 0; i < nFrames; i++) {
        if (raw[i]) {
          voiceCount++;
          silenceCount = 0;
        } else {
          silenceCount++;
          voiceCount = 0;
        }

        if (!inSpeech) {
          if (voiceCount >= startHang) {
            inSpeech = true;
            labels[i] = 1;
          }
        } else {
          labels[i] = 1;
          if (silenceCount >= endHang) {
            inSpeech = false;
            labels[i] = 0;
          }
        }
      }

      return { labels, frameTimes: Array.from(frameTimes) };
    }

    async function runWebRtcVad(int16k, frameMs, mode) {
      const mod = await loadWebRtcVad();
      // @ozymandiasthegreat/vad exports a default async factory function that returns the VAD class.
      let VADClass;
      if (typeof mod.default === "function") {
        VADClass = await mod.default();
      } else if (mod.VAD) {
        VADClass = mod.VAD;
      }

      if (!VADClass) {
        throw new Error("Failed to load VAD class from module. keys: " + Object.keys(mod).join(", "));
      }

      const VADEvent = mod.VADEvent;

      // Instantiate
      const vadInst = new VADClass(Number(mode), CFG.TARGET_SR);


      const frameSamples = Math.round(CFG.TARGET_SR * (Number(frameMs) / 1000));
      const nFrames = Math.floor(int16k.length / frameSamples);

      const labels = new Uint8Array(nFrames);
      const frameTimes = new Float32Array(nFrames);

      const tStart = performance.now();
      for (let i = 0; i < nFrames; i++) {
        const off = i * frameSamples;
        const frame = int16k.subarray(off, off + frameSamples);

        const t0 = performance.now();
        const ev = vadInst.processFrame(frame);
        frameTimes[i] = performance.now() - t0;

        labels[i] = (ev === VADEvent.VOICE) ? 1 : 0;
      }
      const tEnd = performance.now();
      vadInst.destroy();

      return {
        labels,
        frameTimes: Array.from(frameTimes),
        totalMs: tEnd - tStart
      };
    }

    // === Silero NonRealTimeVAD (vad-web) ===
    async function runSileroVad(floatInput, inputSampleRate, options) {
      if (!window.vad?.NonRealTimeVAD) {
        throw new Error("vad.NonRealTimeVAD not found (bundle load failed?)");
      }

      if (window.ort?.env?.wasm) {
        window.ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.22.0/dist/";
      }

      const modelURL = "https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.29/dist/silero_vad_v5.onnx";

      const frameSamples = Number(options.frameSamples);
      const gridMs = Number(options.gridMs);

      const framesForMs = (ms) => Math.max(1, Math.round((ms / 1000) * CFG.TARGET_SR / frameSamples));
      const minSpeechFrames = framesForMs(options.minSpeechMs);
      const preSpeechPadFrames = framesForMs(options.preSpeechPadMs);
      const redemptionFrames = framesForMs(options.redemptionMs);

      const nrt = await window.vad.NonRealTimeVAD.new({
        positiveSpeechThreshold: Number(options.pos),
        negativeSpeechThreshold: Number(options.neg),
        frameSamples,
        minSpeechFrames,
        preSpeechPadFrames,
        redemptionFrames,
        modelURL,
        modelFetcher: async (path) => {
          const res = await fetch(path);
          if (!res.ok) throw new Error(`model fetch failed: ${res.status}`);
          return await res.arrayBuffer();
        },
      });

      const segments = [];
      const tStart = performance.now();
      for await (const seg of nrt.run(floatInput, inputSampleRate)) {
        segments.push({ startMs: seg.start, endMs: seg.end });
      }
      const tEnd = performance.now();

      const totalMs = Math.round((floatInput.length / inputSampleRate) * 1000);
      const labels = segmentsToGrid(segments, totalMs, gridMs);

      return { segments, labels, totalMs: tEnd - tStart };
    }

    function drawTimeline(rows, totalMs) {
      const ctx = timeline.getContext("2d");
      const w = timeline.width;
      const h = timeline.height;

      ctx.clearRect(0, 0, w, h);
      ctx.fillStyle = "#070a11";
      ctx.fillRect(0, 0, w, h);

      const leftPad = 110;
      const topPad = 14;
      const rowH = 38;
      const barH = 16;

      // axis
      ctx.strokeStyle = "rgba(255,255,255,0.15)";
      ctx.beginPath();
      ctx.moveTo(leftPad, topPad - 4);
      ctx.lineTo(leftPad, h - 12);
      ctx.stroke();

      // time ticks every 1s
      const ticks = Math.max(1, Math.floor(totalMs / 1000));
      ctx.fillStyle = "rgba(255,255,255,0.35)";
      ctx.font = "12px ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace";
      for (let s = 0; s <= ticks; s++) {
        const x = leftPad + (w - leftPad - 14) * (s * 1000 / totalMs);
        ctx.strokeStyle = "rgba(255,255,255,0.08)";
        ctx.beginPath();
        ctx.moveTo(x, topPad - 2);
        ctx.lineTo(x, h - 12);
        ctx.stroke();
        ctx.fillText(`${s}s`, x + 2, 12);
      }

      rows.forEach((r, idx) => {
        const y0 = topPad + idx * rowH;
        ctx.fillStyle = "rgba(255,255,255,0.75)";
        ctx.fillText(r.name, 12, y0 + 16);

        ctx.fillStyle = r.color;
        for (const seg of r.segments) {
          const x0 = leftPad + (w - leftPad - 14) * (seg.startMs / totalMs);
          const x1 = leftPad + (w - leftPad - 14) * (seg.endMs / totalMs);
          const bw = Math.max(1, x1 - x0);
          ctx.fillRect(x0, y0 + 18, bw, barH);
        }

        ctx.strokeStyle = "rgba(255,255,255,0.08)";
        ctx.beginPath();
        ctx.moveTo(8, y0 + rowH - 2);
        ctx.lineTo(w - 8, y0 + rowH - 2);
        ctx.stroke();
      });
    }

    function setStatus(html) { statusEl.innerHTML = html; }

    function addMetricRow({ name, totalMs, rtf, segments, speechSec, p50, p95, prf }) {
      const tr = document.createElement("tr");
      tr.innerHTML = `
      <td><b>${name}</b></td>
      <td class="right mono">${fmtMs(totalMs)}</td>
      <td class="right mono">${rtf.toFixed(3)}</td>
      <td class="right mono">${segments}</td>
      <td class="right mono">${speechSec.toFixed(3)}</td>
      <td class="right mono">${isFinite(p50) ? fmtMs(p50) : "-"} / ${isFinite(p95) ? fmtMs(p95) : "-"}</td>
      <td class="right mono">${prf ? `${prf.prec.toFixed(3)} / ${prf.rec.toFixed(3)} / ${prf.f1.toFixed(3)}` : "-"}</td>
    `;
      metricsTableBody.appendChild(tr);
    }

    function clearMetrics() { metricsTableBody.innerHTML = ""; }

    async function decodeAudioFile(file) {
      const ab = await file.arrayBuffer();
      const blobUrl = URL.createObjectURL(file);
      playerEl.src = blobUrl;

      const ac = new (window.AudioContext || window.webkitAudioContext)();
      const buf = await ac.decodeAudioData(ab.slice(0));
      await ac.close();

      const mono = toMonoFloat32(buf);
      return { mono, sampleRate: buf.sampleRate, durationSec: buf.duration };
    }

    async function checkLibs() {
      const okVadWeb = !!window.vad;
      let okWebRtc = false;
      try {
        await loadWebRtcVad();
        okWebRtc = true;
      } catch { }
      const ok = okVadWeb && okWebRtc;
      libStatusEl.textContent = ok ? "libs: ready" : "libs: partial";
      libStatusEl.className = "pill " + (ok ? "ok" : "warn");
    }

    let lastExport = null;
    let gtSegments = null;

    gtFileEl.addEventListener("change", async () => {
      gtSegments = null;
      const f = gtFileEl.files?.[0];
      if (!f) return;
      try {
        const txt = await f.text();
        const json = JSON.parse(txt);
        if (!Array.isArray(json)) throw new Error("GT must be an array");
        gtSegments = json.map(x => ({ startMs: Number(x.startMs), endMs: Number(x.endMs) }))
          .filter(x => Number.isFinite(x.startMs) && Number.isFinite(x.endMs) && x.endMs > x.startMs);
        setStatus(`<span class="good">GT loaded:</span> ${gtSegments.length} segments`);
      } catch (e) {
        setStatus(`<span class="bad">GT parse error:</span> ${e.message ?? e}`);
      }
    });

    runBtn.addEventListener("click", async () => {
      let f = audioFileEl.files?.[0];
      if (!f) {
        try {
          setStatus(`無選擇音檔，使用預設範例音檔 (audio.wav)...`);
          const res = await fetch("audio.wav?t=" + new Date().getTime());
          if (!res.ok) throw new Error("Default audio fetch failed");
          const blob = await res.blob();
          f = new File([blob], "audio.wav", { type: "audio/wav" });
        } catch (e) {
          setStatus(`<span class="bad">請先選擇音檔</span> (預設音檔讀取失敗: ${e.message})`);
          return;
        }
      }

      runBtn.disabled = true;
      exportBtn.disabled = true;
      exportBox.value = "";
      clearMetrics();
      await checkLibs();

      const mode = $("webrtcMode").value;
      const frameMs = Number($("webrtcFrameMs").value);

      const sileroPos = Number($("sileroPos").value);
      const sileroNeg = Number($("sileroNeg").value);
      const sileroFrameSamples = Number($("sileroFrameSamples").value);
      const sileroMinSpeechMs = Number($("sileroMinSpeechMs").value);
      const sileroPadMs = Number($("sileroPadMs").value);
      const sileroRedeemMs = Number($("sileroRedeemMs").value);

      const energyThr = Number($("energyThr").value);
      const energyStartHang = Number($("energyStartHang").value);
      const energyEndHang = Number($("energyEndHang").value);

      try {
        setStatus(`解碼音檔中…`);
        const { mono, sampleRate, durationSec } = await decodeAudioFile(f);

        setStatus(`Resample → 16kHz mono… (input SR=${sampleRate}Hz, duration=${durationSec.toFixed(2)}s)`);
        const float16k = resampleLinear(mono, sampleRate, CFG.TARGET_SR);

        const totalMs = (float16k.length / CFG.TARGET_SR) * 1000;
        const int16k = floatToInt16PCM(float16k);

        const gtGrid = gtSegments ? segmentsToGrid(gtSegments, totalMs, CFG.GRID_MS) : null;

        // Energy baseline
        setStatus(`Running Energy baseline…`);
        const tE0 = performance.now();
        const energy = runEnergyVad(float16k, CFG.GRID_MS, energyThr, energyStartHang, energyEndHang);
        const energySegs = segmentsFromFrameLabels(energy.labels, CFG.GRID_MS);
        const tE1 = performance.now();

        // WebRTC VAD
        setStatus(`Running WebRTC VAD (mode=${mode}, frame=${frameMs}ms)…`);
        const webrtcOut = await runWebRtcVad(int16k, frameMs, mode);
        const webrtcSegs = segmentsFromFrameLabels(webrtcOut.labels, frameMs);

        // Silero (NonRealTimeVAD)
        setStatus(`Running Silero (vad-web NonRealTimeVAD)…`);
        const sileroOut = await runSileroVad(float16k, CFG.TARGET_SR, {
          pos: sileroPos,
          neg: sileroNeg,
          frameSamples: sileroFrameSamples,
          minSpeechMs: sileroMinSpeechMs,
          preSpeechPadMs: sileroPadMs,
          redemptionMs: sileroRedeemMs,
          gridMs: CFG.GRID_MS
        });

        // Metrics
        const audioDurSec = float16k.length / CFG.TARGET_SR;

        const energyStats = frameTimesStats(energy.frameTimes);
        const webrtcStats = frameTimesStats(webrtcOut.frameTimes);

        const energyPrf = gtGrid ? prf1(segmentsToGrid(energySegs, totalMs, CFG.GRID_MS), gtGrid) : null;
        const webrtcPrf = gtGrid ? prf1(segmentsToGrid(webrtcSegs, totalMs, CFG.GRID_MS), gtGrid) : null;
        const sileroPrf = gtGrid ? prf1(sileroOut.labels, gtGrid) : null;

        addMetricRow({
          name: "Energy baseline",
          totalMs: tE1 - tE0,
          rtf: (tE1 - tE0) / (audioDurSec * 1000),
          segments: energySegs.length,
          speechSec: sumSpeechSeconds(energySegs),
          p50: energyStats.p50,
          p95: energyStats.p95,
          prf: energyPrf
        });

        addMetricRow({
          name: `WebRTC VAD (mode=${mode}, ${frameMs}ms)`,
          totalMs: webrtcOut.totalMs,
          rtf: webrtcOut.totalMs / (audioDurSec * 1000),
          segments: webrtcSegs.length,
          speechSec: sumSpeechSeconds(webrtcSegs),
          p50: webrtcStats.p50,
          p95: webrtcStats.p95,
          prf: webrtcPrf
        });

        addMetricRow({
          name: `Silero (vad-web NonRealTimeVAD)`,
          totalMs: sileroOut.totalMs,
          rtf: sileroOut.totalMs / (audioDurSec * 1000),
          segments: sileroOut.segments.length,
          speechSec: sumSpeechSeconds(sileroOut.segments),
          p50: NaN,
          p95: NaN,
          prf: sileroPrf
        });

        // Timeline rows
        const rows = [];
        if (gtSegments) rows.push({ name: "GT", segments: gtSegments, color: "rgba(255,255,255,0.65)" });
        rows.push({ name: "Energy", segments: energySegs, color: "rgba(253,176,34,0.85)" });
        rows.push({ name: "WebRTC", segments: webrtcSegs, color: "rgba(50,213,131,0.85)" });
        rows.push({ name: "Silero", segments: sileroOut.segments, color: "rgba(96,165,250,0.85)" });

        drawTimeline(rows, totalMs);

        // Export payload
        lastExport = {
          meta: {
            createdAt: new Date().toISOString(),
            browser: navigator.userAgent,
            input: { fileName: f.name, inputSampleRate: sampleRate, durationSec: audioDurSec },
            targetSampleRate: CFG.TARGET_SR,
            gridMs: CFG.GRID_MS
          },
          config: {
            webrtc: { mode: Number(mode), frameMs },
            silero: { pos: sileroPos, neg: sileroNeg, frameSamples: sileroFrameSamples, minSpeechMs: sileroMinSpeechMs, preSpeechPadMs: sileroPadMs, redemptionMs: sileroRedeemMs },
            energy: { rmsThr: energyThr, startHangoverFrames: energyStartHang, endHangoverFrames: energyEndHang }
          },
          results: {
            groundTruth: gtSegments ?? null,
            energy: { segments: energySegs },
            webrtc: { segments: webrtcSegs },
            silero: { segments: sileroOut.segments }
          }
        };

        exportBtn.disabled = false;

        setStatus(`
        <b>Done.</b><br/>
        audio: <span class="mono">${audioDurSec.toFixed(3)}s</span><br/>
        tips：如果 WebRTC import 失敗，通常是瀏覽器阻擋 ESM / CDN；換 Chrome 或改版本試試。
      `);

      } catch (e) {
        console.error(e);
        setStatus(`<span class="bad">Error:</span> ${e?.message ?? e}`);
      } finally {
        runBtn.disabled = false;
      }
    });

    exportBtn.addEventListener("click", () => {
      if (!lastExport) return;
      exportBox.value = JSON.stringify(lastExport, null, 2);
    });

    // First check
    await checkLibs();
  </script>

</body>

</html>